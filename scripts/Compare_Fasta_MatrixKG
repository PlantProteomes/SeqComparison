#!/bin/env python3

from fileinput import filename
import re
from tabnanny import filename_only
from tkinter.tix import COLUMN
from turtle import update
from Bio import SeqIO
import json
import argparse
from numpy import matrix, zeros
import pandas as pd


class FastaStats:

    def __init__(self):
        self.seqlist = []
        self.final_variable_row = []
        self.zeroes = []
        self.variable_row = []
        self.zerocounter = 0
        self.comparenums = []
        self.entry_counter = 0
        self.entry_counter_list = []
        self.stats = {}
        self.df_final = pd.DataFrame(columns=["Source", "Sequences", "Unique"])
        self.split_files = []
        self.filename = []
        self.titlenames = []
        for data_type in ['identifiers', 'sequences', 'descriptions']:
            self.stats[data_type] = {
                'n_redundant_entries': 0,
                'nonredundant_entries': {}

            }

    # this function updates count of redundant identifiers

    def add_datum(self, data_type, value):
        if value in self.stats[data_type]['nonredundant_entries']:
            self.stats[data_type]['n_redundant_entries'] += 1
            self.stats[data_type]['nonredundant_entries'][value] += 1
        else:
            self.stats[data_type]['nonredundant_entries'][value] = 1

    def read(self, filename):

        # this will open specified file
        with open(filename) as infile:

            print(f"INFO: Reading {filename}")

            # parses through records line by line
            for record in SeqIO.parse(infile, 'fasta'):
                sequence = str(record.seq)
                self.seqlist.append(sequence)
                self.entry_counter += 1

                # this line separates the identifier and the description into 2 groups by the space
                # record is a fasta object
                match = re.match(r'^(\S+)\s*(.*)$', record.description)
                if match:  # if this line can be separated and parsed this way
                    identifier = match.group(1)
                    description = match.group(2)

                    self.add_datum('identifiers', identifier)
                    self.add_datum('sequences', sequence)
                    self.add_datum('descriptions', sequence)

                else:
                    print(
                        f"ERROR: Unable to parse description line: {record.description}")
                    exit()
        self.entry_counter_list.append(self.entry_counter)

    def compare(self, list1, list2):
        same_seq = 0
        dict2 = dict.fromkeys(list2, True)
        for item in list1:
            if item in dict2:
                same_seq += 1
        self.comparenums.append(same_seq)

    def parse_files_argument(self, files):
        print("Parsing input title=filename arguments")
        self.update_row_counter = 0
        self.split_files = []
        for title_file in files:
            try:
                title, filename = title_file.split('=')
            except:
                print(
                    f"ERROR: Parameter '{title_file}' should have the format TITLE=FILENAME (e.g. Mito=mitochondria.2.fasta)")
                exit(1)
            split_file = {'title': title, 'filename': filename}
            splitfile_merge_columns = pd.DataFrame(columns=[title])
            self.split_files.append(split_file)
            self.filename.append(filename)
            self.titlenames.append(title)
            self.df_final = pd.concat(
                [self.df_final, splitfile_merge_columns], axis=0)
            self.zeroes.append(0)
            self.update_row_counter += 1


##########################################################################


def main():

    # Add the arguments
    argparser = argparse.ArgumentParser(
        description='Find duplicate identifiers, sequences, and descriptions in a FASTA file and create a matrix for them')
    argparser.add_argument('--show_duplicate_identifiers', action='count',
                           help='If set, print the duplicate identifiers and their count in the input file')
    argparser.add_argument('--show_duplicate_sequences', action='count',
                           help='If set, print the duplicate sequences and their count in the input file')
    argparser.add_argument('--show_duplicate_descriptions', action='count',
                           help='If set, print the duplicate descriptions and their count in the input file')
    argparser.add_argument('--show_total_reads', action='count',
                           help='If set, print the total number of rows in the input file')
    argparser.add_argument('files', type=str, nargs='+',
                           help='Filename of the FASTA file to read')

  #  argparser.add_argument('matrix build', type=int, nargs='+',
  #                         help='Enter a number larger than 3')

    args = argparser.parse_args()

    matrix = FastaStats()
    matrix2 = FastaStats()
    matrix.parse_files_argument(args.files)
    matrix2.parse_files_argument(args.files)
    matrix.final_variable_row = matrix.variable_row
    counter = 0

    temp_list = []
    for i in range(0, len(args.files)):
        matrix.read(matrix.filename[i])
        matrix.variable_row = [matrix.titlenames[i], matrix.entry_counter_list[i], len(
            matrix.stats['sequences']['nonredundant_entries'])]

        for j in range(i+1, len(args.files)):
            matrix2.read(matrix.filename[j])
            matrix.compare(matrix.seqlist, matrix2.seqlist)
            matrix2.seqlist.clear()

        temp_list.append(None)
        matrix.variable_row.extend(temp_list)

        matrix.variable_row.extend(matrix.comparenums)

        matrix.comparenums.clear()
        print(matrix.variable_row)
        matrix.df_final.loc[i] = matrix.variable_row
        matrix.variable_row.clear()
        matrix.seqlist.clear()
    print(matrix.df_final)


# return


if __name__ == "__main__":
    main()
